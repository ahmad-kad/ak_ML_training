{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (1.5.16)\n",
      "Requirement already satisfied: six>=1.10 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (4.66.1)\n",
      "Requirement already satisfied: python-slugify in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (1.26.13)\n",
      "Requirement already satisfied: bleach in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = {\"username\":\"ahmadkaddoura\",\"key\":\"aca490a33efaa2e266410a1833167d66\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-patent-phrase-to-phrase-matching.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "import zipfile,kaggle\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path('us-patent-phrase-to-phrase-matching')\n",
    "kaggle.api.competition_download_cli(str(path))\n",
    "zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../fastai/us-patent-phrase-to-phrase-matching/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['input'] = f'Text1: {df.context} ; Text2: {df.target} ; Anc1: {df.anchor}'\\\n",
    "df['input'] = f'Text1: '+ df.context + ' Text2: ' + df.target +' ; Anc1: ' + df.anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Text1: A47 Text2: abatement of pollution ; Anc...\n",
       "1    Text1: A47 Text2: act of abating ; Anc1: abate...\n",
       "2    Text1: A47 Text2: active catalyst ; Anc1: abat...\n",
       "3    Text1: A47 Text2: eliminating process ; Anc1: ...\n",
       "4    Text1: A47 Text2: forest region ; Anc1: abatement\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'microsoft/deberta-v3-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k:\\AI\\ak_tensorflow_collab_training\\.conda\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁hello',\n",
       " '▁my',\n",
       " '▁dear',\n",
       " '▁an',\n",
       " '▁Sally',\n",
       " ',',\n",
       " '▁what',\n",
       " '▁have',\n",
       " '▁you',\n",
       " '▁eaten',\n",
       " '▁for',\n",
       " '▁breakfast',\n",
       " '▁today',\n",
       " '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"hello my dear an Sally, what have you eaten for breakfast today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x) : return tokz(x['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565649810ad9419a8a88ba59ad70ca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "toks_ds = ds.map(tok_func,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Text1: A47 Text2: abatement of pollution ; Anc1: abatement',\n",
       " [1,\n",
       "  7655,\n",
       "  435,\n",
       "  294,\n",
       "  336,\n",
       "  5753,\n",
       "  7655,\n",
       "  445,\n",
       "  294,\n",
       "  47284,\n",
       "  265,\n",
       "  6435,\n",
       "  2600,\n",
       "  816,\n",
       "  1207,\n",
       "  435,\n",
       "  294,\n",
       "  47284,\n",
       "  2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = toks_ds[0]\n",
    "row['input'],row['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99050"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.vocab['pollution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_ds=toks_ds.rename_columns({'score':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('us-patent-phrase-to-phrase-matching/train.csv')\n",
    "eval_df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = toks_ds.train_test_split(0.25,seed =10)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6e18f602ef452b8834719770f729f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "eval_df['input'] = 'TEXT1: ' + eval_df.context + '; TEXT2: ' + eval_df.target + '; ANC1: ' + eval_df.anchor\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (2.1.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: requests in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in k:\\ai\\ak_tensorflow_collab_training\\.conda\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs= 128\n",
    "epochs = 5\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments('outputs',\n",
    "                         learning_rate=lr,\n",
    "                         warmup_ratio=.1,\n",
    "                         lr_scheduler_type='cosine', \n",
    "                         fp16=True,\n",
    "                         evaluation_strategy=\"epoch\",\n",
    "                         per_device_eval_batch_size=bs*2,\n",
    "                         per_device_train_batch_size=bs,\n",
    "                         num_train_epochs=epochs,\n",
    "                         weight_decay=.01,\n",
    "                         report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm,num_labels=1)\n",
    "trainer = Trainer(model,args,train_dataset=dds['train'],eval_dataset=dds['test'],tokenizer=tokz,compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0312733f1f4e3586f2c62ba99a81f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780723a58f364d98a85f12ef1060e15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.024191400036215782, 'eval_pearson': 0.8013640431969737, 'eval_runtime': 0.9479, 'eval_samples_per_second': 9619.995, 'eval_steps_per_second': 37.978, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4111fe091674970a48aa61384574131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.023879537358880043, 'eval_pearson': 0.8239720911991398, 'eval_runtime': 0.9229, 'eval_samples_per_second': 9880.604, 'eval_steps_per_second': 39.007, 'epoch': 2.0}\n",
      "{'loss': 0.0314, 'learning_rate': 5.1388762323647767e-05, 'epoch': 2.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3de6e71d02d4c0ba455c94f35fc3ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02206900715827942, 'eval_pearson': 0.8346824154723499, 'eval_runtime': 0.9628, 'eval_samples_per_second': 9471.167, 'eval_steps_per_second': 37.39, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bb50fd9c98419da44aa3658d7f1c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.022259224206209183, 'eval_pearson': 0.839742604711239, 'eval_runtime': 0.9557, 'eval_samples_per_second': 9541.215, 'eval_steps_per_second': 37.667, 'epoch': 4.0}\n",
      "{'loss': 0.0124, 'learning_rate': 1.038448832995451e-06, 'epoch': 4.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556419331f4e4a5aa0e07b4fc46c86ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.021980004385113716, 'eval_pearson': 0.8398912025845181, 'eval_runtime': 0.9642, 'eval_samples_per_second': 9457.135, 'eval_steps_per_second': 37.335, 'epoch': 5.0}\n",
      "{'train_runtime': 65.3835, 'train_samples_per_second': 2091.813, 'train_steps_per_second': 16.365, 'train_loss': 0.02115028066055797, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1f6edda521485d9c6c979639c5a9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55957031],\n",
       "       [0.61279297],\n",
       "       [0.25048828],\n",
       "       ...,\n",
       "       [0.54736328],\n",
       "       [0.74658203],\n",
       "       [0.5390625 ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55957031],\n",
       "       [0.61279297],\n",
       "       [0.25048828],\n",
       "       ...,\n",
       "       [0.54736328],\n",
       "       [0.74658203],\n",
       "       [0.5390625 ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.clip(preds, 0, 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6ae244e6834bc895a2882df686acb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1087728"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
